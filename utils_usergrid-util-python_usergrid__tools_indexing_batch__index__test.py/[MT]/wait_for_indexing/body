def wait_for_indexing(created_map, q_url, sleep_time=0.0):
    logger.info(('Waiting for indexing of [%s] entities...' % len(created_map)))
    count_missing = 100
    start_time = datetime.datetime.now()
    while (count_missing > 0):
        entity_map = {}
        r = session.get(q_url)
        res = r.json()
        entities = res.get('entities', [])
        now_time = datetime.datetime.now()
        elapsed = (now_time - start_time)
        logger.info(('Found [%s] of [%s] ([%s] missing) after [%s] entities at url: %s' % (len(entities), len(created_map), (len(created_map) - len(entities)), elapsed, q_url)))
        count_missing = 0
        for entity in entities:
            entity_map[entity.get('uuid')] = entity
        for (uuid, created_entity) in created_map.iteritems():
            if (uuid not in entity_map):
                count_missing += 1
                logger.info(('Missing uuid=[%s] Id=[%s] total missing=[%s]' % (uuid, created_entity.get('id'), count_missing)))
        if (count_missing > 0):
            logger.info(('Waiting for indexing, count_missing=[%s] Total time [%s] Sleeping for [%s]s' % (elapsed, count_missing, sleep_time)))
            time.sleep(sleep_time)
    stop_time = datetime.datetime.now()
    logger.info(('All entities found after %s' % (stop_time - start_time)))
