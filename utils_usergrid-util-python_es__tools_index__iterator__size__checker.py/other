import json
import re
import traceback
from multiprocessing.pool import Pool
import requests
index_url_template = 'http://localhost:9200/{index_name}/_search?size={size}&from={from_var}&q=-edgeName:zzzcollzzz|logs'
index_names = ['es-index-name']
baas_url = 'http://localhost:8080/org/{app_id}/{collection}/{entity_id}'
field_part_map = {'mockdata': 'mockData', }
my = {'foo': {'bar': {'color': 'red', }, }, }
fields = [{'name': 'foo.size', 'string': '2', }, {'name': 'foo.bar.size', 'long': 2, }]
POOL_SIZE = 4
counter = 0
size = (POOL_SIZE * 10)
size = 1000
total_docs = 167501577
start_from = 0
from_var = 0
page = 0
work_items = []
pool = Pool(POOL_SIZE)
keep_going = True
while keep_going:
    work_items = []
    if (from_var > total_docs):
        keep_going = False
        break
    from_var = (start_from + (page * size))
    page += 1
    for index_name in index_names:
        index_url = index_url_template.format(index_name=index_name, size=size, from_var=from_var)
        print ('Getting URL: ' + index_url)
        r = requests.get(index_url)
        if (r.status_code != 200):
            print r.text
            exit()
        response = r.json()
        hits = response.get('hits', {}).get('hits')
        re_app_id = re.compile('appId\\((.+),')
        re_ent_id = re.compile('entityId\\((.+),')
        re_type = re.compile('entityId\\(.+,(.+)\\)')
        print ('Index: %s | hits: %s' % (index_name, len(hits)))
        if (len(hits) == 0):
            keep_going = False
            break
        for hit_data in hits:
            source = hit_data.get('_source')
            application_id = source.get('applicationId')
            app_id_find = re_app_id.findall(application_id)
            if (len(app_id_find) > 0):
                app_id = app_id_find[0]
                entity_id_tmp = source.get('entityId')
                entity_id_find = re_ent_id.findall(entity_id_tmp)
                entity_type_find = re_type.findall(entity_id_tmp)
                if ((len(entity_id_find) > 0) and (len(entity_type_find) > 0)):
                    entity_id = entity_id_find[0]
                    collection = entity_type_find[0]
                    fields_to_update = []
                    for field in source.get('fields'):
                        if (field.get('name')[(-5):] == '.size'):
                            fields_to_update.append(field)
                            print json.dumps(source)
                            work_items.append((app_id, collection, entity_id, fields_to_update))
                    counter += 1
    print ('Work Items: %s' % len(work_items))
    try:
        pool.map(work, work_items)
    except:
        print traceback.format_exc()
        try:
            pool.map(work, work_items)
        except:
            pass
    print 'Work Done!'
print ('done: %s' % counter)
